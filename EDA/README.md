# Binance Market Data - Exploratory Data Analysis (EDA)

This Apache Zeppelin notebook (`Binance-EDA.zpln`) performs scalable exploratory data analysis (EDA) on Binance crypto trading data using PySpark.

---

## ğŸ“ˆ Whatâ€™s in the Notebook?

The notebook covers:

### ğŸ“¦ Data Loading
- Load from S3 or local disk (Parquet format)
- Schema inspection and first few rows

### ğŸ§ª Basic EDA
- Descriptive statistics (`open`, `high`, `low`, `close`, `volume`)
- Time range check

### ğŸ“… Daily Aggregation
- First open, last close, max high, min low
- Average closing price and total daily volume
- **Visualization**: Display daily OHLC summary using `z.show()`

### ğŸ“Š Moving Average
- 7-day moving average window for smoothing trends
- **Visualization**: Display moving average result using `z.show()`

### ğŸ” Buy Pressure Ratio
- Ratio of taker buy quote volume to total quote asset volume
- Indicates market pressure
- **Visualization**: Display daily buy pressure ratio using `z.show()`

### ğŸŒ©ï¸ Volatility (Candle Range)
- High minus low, averaged per day
- **Visualization**: Display volatility pattern using `z.show()`

### âš ï¸ Outlier Detection
- Detect candles with the largest high-low range
- **Visualization**: Show outliers using `z.show()`

### ğŸ“ˆ Daily Trade Counts
- Aggregated number of trades per day
- **Visualization**: Display daily trades using `z.show()`

### ğŸ•’ Hourly Patterns
- Average closing price and volume by hour of day
- **Visualization**: Display hourly trading patterns using `z.show()`

---

## ğŸ§  Tech Stack

- **Apache Zeppelin**: Notebook interface and visualizations
- **PySpark**: Distributed processing of large-scale data
- **Spark SQL**: Structured querying for efficient group-by, filters, and aggregation

---

## ğŸ“‚ How to Use

1. Open Apache Zeppelin
2. Click **Import Note**
3. Upload `Binance-EDA.zpln`
4. Run each paragraph to generate charts and tables

---

## ğŸ“ Notes

- `.zpln` files are Zeppelin-specific and must be viewed inside Zeppelin
- Charts (from `z.show()`) will not be visible on GitHub, only inside Zeppelin UI
- Data format expected: Parquet, with fields like `open_time`, `close`, `high`, `low`, `volume`, etc.

---

## ğŸ§ª Optional Enhancements

- Add moving averages with different windows (14, 30 days)
- Compare different trading pairs or time periods
- Save cleaned/aggregated data back to S3 or local storage

